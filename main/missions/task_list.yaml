auto imitator bootstrapping:
    - DONE find a baselinethat performs well on a custom environment
    - DONE record data: 
        - use the custom preprocessed breakout
        - save the unpreprocessed frames
        - using baselines a2c
    - DONE batch the newly recorded data
    - DONE train the auto imitator on the compressed env:
        - still only at 61% accuracy though ...
    - transfer the improvement:
        - DONE try training the chao's DQN on 0 to 255 normally, record the curve
        - DONE try training the chao's DQN but only on the latent space of auto imitator, record the curve
        - DONE try training the chao's DQN but just transfer weights for the first half, record the curve
        - try transfering the latent space directly from the baselines A2C to chao dqn
        - hack the a2c network by transfering much of the network, but randomizing everything past the latent space
        - keep track of the rewards/training time curve
    - train the auto imitator on the uncompressed env:
        - create a custom frame que
        - map the from the custom frame que to an action
        - might need to have additional loss based on auto-decoding the input to improve learning speed
        - might need dynamic image augmentation to prevent/reduce overfitting
        - might need more data (dynamic training, collect a number of episodes then randomly sample from them)
    - attempt to use auto imitator as an alternative preprocessor:
        - train chao's dqn based on the auto imitated latent space instead of the preprocessed env
        - HARD alternative: somehow hack the baselines a2c to ignore the normal input and use the preprocessed input instead
        - maybe attempt to train my own agent again
    - attempt transfering the preprocessor to a new domain, such as enduro:
        - will definitely need the imitator to have the auto-decoding loss
        - might need a variational auto encoder to provide more generalized learning